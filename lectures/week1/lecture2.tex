\documentclass[10pt]{beamer}
\usepackage{amsmath,amsfonts,microtype,nicefrac,amssymb, amsthm,centernot}
\usefonttheme{professionalfonts}
\usefonttheme{serif}

\usepackage{palatino}
\usepackage{mathpazo} % or: {newpxtext,newpxmath}
\renewcommand\familydefault{\rmdefault}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{bm}

\usepackage{tikz}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows,shapes}
\usepackage{caption, subcaption}

%% BEAMER BUTTON
%\setbeamertemplate{button}{\tikz
%\node[
%	inner xsep = 2pt, 
%	draw = structure!0, 
%	fill = myblue, 
%	rounded corners = 4pt]{\color{white} \tiny\insertbuttontext};
%}


%% ALGORITHM 
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{multimedia}

%% THEME
\usetheme[frametitleformat=regular,titleformat=regular]{Madrid}
\setbeamerfont{frametitle}{shape=\normalfont}
\setbeamerfont{title}{shape=\normalfont}

%% PATHS
\graphicspath{{./results/}}
\makeatletter
\def\input@path{{../draft/tables/latexData/}}
\makeatother

%% FIGURE ENVIRONMENT 
\usepackage{booktabs,siunitx}

\usepackage{pgfplots} 
%\usepackage[outdir=./figures]{epstopdf}
\usepackage{epstopdf}
\usepackage{float}
\usepackage{graphicx}

\usepackage[absolute,overlay]{textpos}

%% COLORS
%% LINKS
\definecolor{myred}{RGB}{163,32,45}
\definecolor{navyblue}{rgb}{0.05,0.2,0.70}
\definecolor{myblue}{RGB}{0,51,150}
\definecolor{myorange}{RGB}{255,140,0}
\definecolor{myref}{RGB}{160,160,160}
\definecolor{shock}{RGB}{0, 125, 34}%{50, 168, 82}

%% TRANSPARENCY

\usepackage{transparent}

%% BEAMER TEMPLATE
\usetheme{Boadilla}

\makeatother
\setbeamertemplate{itemize items}{\large\raisebox{-0.25ex}{\textbullet}}
\setbeamertemplate{itemize subitem}{\footnotesize\raisebox{0.15ex}{--}}
\setbeamertemplate{itemize subsubitem}{\Tiny\raisebox{0.7ex}{$\blacktriangleright$}}
%\setbeamertemplate{itemize subsubitem}{\color{yellow}$\blacksquare$}

\setbeamertemplate{enumerate item}[default]
\setbeamertemplate{enumerate subitem}{\textbullet}
\setbeamertemplate{footline}{}
\makeatletter
\setbeamertemplate{navigation symbols}{}


%% FORMATTING AUTHORS
%\usepackage{authblk}
\usepackage{url}
\usepackage{multirow}
\usepackage{array}

%% FRAME ITEMIZE SPACING
\usepackage{xpatch}

\xpatchcmd{\itemize}
{\def\makelabel}
{\setlength{\itemsep}{2.5ex}\def\makelabel}
{}
{}

\xpatchcmd{\enumerate}
{\def\makelabel}
{\setlength{\itemsep}{10ex}\def\makelabel}
{}
{}

%% APPENDIX 
\usepackage{appendixnumberbeamer}


%% TITLE AND OPENING
\title{\large Lecture 2}
\subtitle{Dynamics: Continuous Time}
\author{Andreas Schaab}
\date{}


\begin{document}
\tikzstyle{every picture}+=[remember picture]
%\everymath{\displaystyle}
\thispagestyle{empty}
\maketitle 
\newpage

\addtocounter{framenumber}{-1}


%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Outline of today's lecture}
\addtocounter{framenumber}{-1}
\begin{enumerate}
\item Ordinary differential equations
\item Prominent examples of differential equations in macro
\item Partial differential equations
\item Solow growth model
\item Continuous-time Markov chains
\item Brownian motion and stochastic differential equations
\end{enumerate}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{1. Ordinary differential equations}
\begin{itemize}
\item Consider the ``discrete-time'' equation 
\begin{equation*}
	X_{t+\Delta t} - X_t = G(X_t, t, \Delta t)
\end{equation*}

\item \textit{Continuous-time limit}: consider the limit as $\Delta t \to 0$
\begin{equation*}
	\dot X_t \equiv \frac{dX}{dt} \equiv \lim_{\Delta t \to 0} \frac{X_{t+\Delta t} - X_t}{\Delta t} = \lim_{\Delta t \to 0} G(X_t, t, \Delta t) \equiv g(X_t, t)
\end{equation*}

\item $\dot X_t = g(X_t)$ is \textit{autonomous} and dropping subscripts: $\dot X = g(X)$

\item This is a \textit{first-order (ordinary) differential equation}, second-order equations are:
\begin{equation*}
	\frac{d^2 X_t}{dt^2} = g \bigg( \frac{dX_t}{dt} , X_t, t \bigg)
\end{equation*}

\item We often consider ODEs in the \textit{time dimension} but ODEs can be defined on any state space (e.g., space dimensions)

\end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Boundary conditions (I)}
\begin{itemize}
\item Boundary conditions are critical for characterizing differential equations

\item Consider an ODE on the time interval $t \in [0, 1]$. We call $[0, 1]$ the \textit{state space}. $(0, 1)$ is the \textit{interior of the state space} and $\{0, 1\}$ is the \textit{boundary}

\item The way to think about it: differential equations are defined on the interior of the state space but not on the boundary

\item To characterize the function that satisfies the ODE on the interior on the \textit{full} state space, we need a set of boundary conditions to also characterize the behavior on the boundary

\item Heuristically: we need as many boundary conditions as the order of the differential equation
\end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Boundary conditions (II)}
\begin{itemize}
\item Similar to discrete-time difference equations: forward equations have initial conditions, backward equations have terminal conditions

\item For ODEs, you will often see the terminology:
\begin{itemize}
	\item \textit{Initial value problems} specify a differential equation for $X_t$ with some \textit{initial condition} $X_0$
	
	\vspace{-3mm}
	\item \textit{Terminal value problems} instead specify $X_T$
\end{itemize}

\item More broadly: We need sufficient information to characterize the function of interest along the boundary

\item Types of boundary conditions: Dirichlet ($X_0 = c$), von-Neumann ($\frac{dX_0}{dt} = c$), reflecting boundaries, ...

\item Boundary conditions are very important and can be very subtle (especially for PDEs)
\end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Linear First-Order ODEs}
\begin{itemize}
\item Consider the equation:
\begin{equation}\label{eq:ODE}
	\dot X(t) = a(t) X(t) + b(t)
\end{equation}

\item If $b(t) = 0$, \eqref{eq:ODE} is a \textit{homogeneous} equation, if $a(t) = a$ and $b(t) = b$ we say \eqref{eq:ODE} has \textit{constant coefficients}

\item Start with $\dot X(t) = a X(t)$, divide by $X(t)$ and integrate with respect to $t$
\begin{align*}
	\int \frac{\dot X(t)}{X(t)} dt &= \int a dt \\
	\log X(t) + c_0 &= a t + c_1 \\
	X(t) &= C e^{a t}
\end{align*}
where $C = e^{c_1 - c_0}$

\item Pin down constant $C$ by using the boundary condition (we need $1$)
\end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}
\begin{itemize}
\item Consider time-varying coefficient with $\dot X(t) = a(t) X(t)$ with initial condition $X(0) = \bar x$

\item Dividing by $X(t)$, integrating, and exponentiating yields 
\begin{equation*}
	X(t) = C e^{ \int_0^t a(s) ds }
\end{equation*}

\item Constant of integration again pinned down by boundary condition: $C = \bar x$

\item Finally, for $\dot X(t) = a X(t) + b$, we find
\begin{equation*}
	X(t) = - \frac{b}{a} + C e^{at}
\end{equation*}
after using change of variables $Y(t) = X(t) + \frac{b}{a}$

\item Many results for systems of linear differential equations: $\dot{\bm X}(t) = \bm A \bm X(t)$

\end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{2. Examples of differential equations in macro}

\textbf{Capital accumulation:}
\begin{equation*}
	\dot K_t = I_t - \delta K_t
\end{equation*}
\begin{itemize}
\item We can always map back and forth between DT and CT

\item In discrete time with \textit{unit} time steps, $K_{t+1} = I_t + (1-\delta) K_t$

\item With arbitrary $\Delta$ time step, $K_{t+\Delta} = K_t + \Delta (I_t - \delta K_t)$

\item Continuous-time limit:
\begin{align*}
	K_{t+\Delta} &= K_t + \Delta (I_t + (1-\delta) K_t \\
	K_{t+\Delta} - K_t &= I_t -\delta K_t \\
	\dot K_t &= I_t -\delta K_t
\end{align*}
\end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}

\begin{itemize}
\item Suppose $\{ I_t \}_{t \geq 0}$ exogenously given

\item Solving this \textit{inhomogeneous equation}, we use \textit{integrating factor}:
\begin{align*}
	\dot K_t + \delta K_t &= I_t  \\
	e^{\int_0^t \delta ds} \dot K_t + e^{\int_0^t \delta ds} \delta K_t &= e^{\int_0^t \delta ds} I_t
\end{align*}

\item Notice that $\int_0^t \delta ds = \delta \int_0^t ds = \delta [s]_0^t = \delta(t - 0) = \delta t$, so 
\begin{align*}
	e^{\delta t} \dot K_t + e^{\delta t} \delta K_t &= e^{\delta t} I_t
\end{align*}

\item We have $e^{\delta t} \dot K_t + e^{\delta t} \delta K_t = \frac{d}{dt} (K_t e^{\delta t})$, integrating:
\begin{align*}
	K_t e^{\delta t} &= \tilde C + \int_0^t e^{\delta s} I_s ds \\
	K_t &= C + \int_0^t e^{- \delta(t-s)} I_s ds
\end{align*}

\item Integrating constant solves initial condition: $C = K_0$
\end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}
\textbf{Wealth dynamics} (\textit{very important equation in this course}):
\begin{equation*}
	\dot a_t = r_t a_t + y_t - c_t
\end{equation*}
\begin{itemize}
\item $r_t$ is the real rate of return on wealth, $y_t$ is income, and $c_t$ is consumption

\item Structure of the equation similar to capital accumulation equation
\end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}
	\textbf{Consumption Euler equation}:
	\begin{equation*}
		\frac{1}{C_t} = \beta R_t\frac{1}{C_{t+1}}
	\end{equation*}
	\begin{itemize}
		\item $\frac{1}{C_t} = u'(C_t)$ is marginal utility with log preferences
		
		\item This is a \textit{backward equation} and requires a terminal condition or transversality condition, i.e., $c_T$ must converge to something
		
		\item Suppose there exists time $T$ s.t. for all $t \geq T$, $C_t = C$
		
		\item Then solve \textit{backwards} from: $\frac{1}{C_{T-1}} = \beta R_{T-1} \frac{1}{C_T}$ or expressed as \textit{time-homogeneous first-order linear difference equation}
		\begin{equation*}
			C_{T-1} = \frac{1}{\beta R_{T-1}} C_T
		\end{equation*}
		
		\item Difference between \textit{forward} and \textit{backward} equations is critical! This is closely related to the idea of \textit{boundary conditions} (much more to come)
	\end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}
	\textbf{New Keynesian Phillips curve}:
	\begin{equation*}
		\dot \pi_t = \rho \pi_t + \kappa x_t
	\end{equation*}
	\begin{itemize}
		\item This is a backward equation that requires a terminal condition
		
		\item As in discrete time, we often consider the $0$ inflation steady state with $\pi_T \to 0$
		
		\item Then we can solve (work this out yourselves):
		\begin{equation*}
			\pi_t = - \kappa \int_t^\infty x_s ds
		\end{equation*}
	\end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{3. A brief intro to partial differential equations}
\begin{itemize}
\item Partial differential equations (PDEs) generalize ODEs to higher-dimensional state spaces

\item PDEs are at the heart of (i) continuous-time \textbf{dynamic programming} and (ii) heterogeneous-agent models in macro

\item PDEs have long been a core tool in physics, applied math, ... \\
$\implies$ increasingly used in economics

\item This class: no self-contained treatment of PDEs \textit{but} we will encounter some simple PDEs
\end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}
\begin{itemize}
\item Consider a function $u(x_1, x_2, \ldots, x_n)$ where $x_1, \ldots, x_n$ are coordinates in $\mathbb R$

\item Partial derivatives of $u(\cdot)$
\begin{equation*}
	\frac{\partial u}{\partial x_i} \equiv \partial_{x_i} u \hspace{5mm} \text{ and } \hspace{5mm} \frac{\partial^2 u}{\partial x_i \partial x_j} = \partial_{x_i x_j} u
\end{equation*}

\item A PDE is an equation in $u$ and its partial derivatives --- fully generally:
\begin{equation*}
	0 = G(u, \partial_{x_1} u, \ldots, \partial_{x_n} u, \partial_{x_1 x_1} u, \ldots )
\end{equation*}

\item The \textit{order} of the PDE, is the order of the highest partial derivative

\item Examples from physics
\begin{itemize}
	\item Heat equation: $\partial_t u = \partial_{xx} u$ (second-order, linear, homogeneous)
	
	\vspace{-3mm}
	\item Wave equation: $\partial_{tt} u = \partial_{xx} u$ (second-order, linear, homogeneous)
	
	\vspace{-3mm}
	\item Transport equation: $\partial_t u = \partial_x u$ (first-order, linear, homogeneous)
\end{itemize}

\item Income distribution ``solves heat equation'', wealth dynamics ``solve transport equations'', dynamic programming often transport + heat 
\end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{4. Solow Growth Model}
\begin{itemize}
\item As before, $Y_t = C_t + I_t$ and 
\begin{equation*}
	\dot K_t = Y_t - C_t - \delta K_t
\end{equation*}

\item Representative firms operates neoclassical production function
\begin{equation*}
	Y_t = F(K_t, L_t, A_t)
\end{equation*}

\item Normalize labor to $L_t = 1$ and hold TFP constant $A_t = A$

\item We again assume constant savings rate: $Y_t - C_t = I_t = s Y_t$

\item Assume Cobb-Douglas $Y_t = A K_t^\alpha$ so equilibrium allocation
\begin{equation*}
	\dot K_t = s A K_t^\alpha - \delta K_t
\end{equation*}
\end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}
\begin{itemize}
\item Steady state is given by
\begin{equation*}
	K^* = \bigg( \frac{sA}{\delta} \bigg)^\frac{1}{1-\alpha}
\end{equation*}

\item Key equilibrium condition in $\dot K_t$ is \textit{non-linear} --- how to proceed?

\item Let $X_t = K_t^{1-\alpha}$, then 
\begin{align*}
	\dot X_t &= (1-\alpha) K_t^{-\alpha} \dot K_t  \\
	&= (1-\alpha) K_t^{-\alpha} ( s A K_t^\alpha - \delta K_t )  \\
	&= (1-\alpha) s A - (1-\alpha) K_t^{1-\alpha} \delta \\
	&= (1-\alpha) s A - (1-\alpha) \delta X_t
\end{align*}

\item Solution with initial condition $X_0$ (work this out):
\begin{equation*}
	X_t = X^* + e^{-(1-\alpha) \delta t} \bigg[ X_0 - X^* \bigg], \;\;\; \text{ where } X^* = \frac{sA}{\delta}
\end{equation*}

\item Transition dynamics (rate of convergence) governed by $-(1-\alpha) \delta)$

\end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{5. Continuous-time Markov chains}

{\small
\begin{itemize}
\item Definition: Let $X = \{X_t\}_{t \geq 0}$ be a sequence of random variables taking values in a finite or countable state space $\mathcal X$. Then $X$ is a \textit{continuous-time Markov chain} if it satisfies the \textit{Markov property}: For any sequence $0 \leq t_1 < t_2 < \ldots < t_n$ of times 
\begin{equation*}
	\mathbb P(X_{t_n} = x \mid X_{t_1}, \ldots, X_{t_{n-1}} ) = \mathbb P(X_{t_n} = x \mid X_{t_{n-1}} )
\end{equation*}


\item Process $X$ is \textit{time-homogeneous} if the conditional probability does not depend on the current time, i.e., for $x, y \in \mathcal X$:
\begin{equation*}
	\mathbb P(X_{t+s} = x \mid X_s = y) = \mathbb P(X_t = x \mid X_0 = y)
\end{equation*}

\item The \textit{transition density} of process $X$ is denoted $p(t, x \mid s, y)$ and is defined as 
\begin{equation*}
	\mathbb P(X_t \in A \mid Y_s = y) = \int_A p(t, x \mid s, y) dx 
\end{equation*}
for any (Borel) set $A \subset \mathcal X$. In words: $p(t, x \mid s, y)$ is the probability (density) that process $X_t$ ends up at $X_t = x$ at time $t$ if it started at $X_s = y$ at time $s$

\item \textit{Condition expectation} can be written as: $\mathbb E[ f(X_t) \mid X_0 = y] = \int p(t, x \mid 0, y) f(x) dx$
\end{itemize}
}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}

\textbf{Example}: 

\vspace{5mm}
{\small
\begin{itemize}
\item Consider the two-state employment process $z_t \in \{z^L, z^H\}$ with transition rates $\lambda^{LH}$ (from L to H) and $\lambda^{HL}$ (from H to L)

\item The associated transition matrix (\textit{generator}) is 
\begin{equation*}
	\mathcal A^z = \begin{pmatrix} - \lambda^{LH} & \lambda^{LH} \\ \lambda^{HL} & -\lambda^{HL} \end{pmatrix}
\end{equation*}

\item Interpretation: households transition \textit{out of} state $i$ at rate $\lambda^{ij}$

\item Notice: In discrete time, Markov transition matrix rows sum to $1$. Here, rows sum to $0$ (\textit{mass preservation})
\end{itemize}
}
\end{frame}




%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{6. Brownian motion and SDEs}

{\small
\textbf{Definition.} Brownian motion $\{B_t\}_{t\geq 0}$ is a stochastic process with properties:
\begin{itemize}
	\item [(i)] $B_0 = 0$
	
	\item [(ii)] (\textit{Independent increments}) For non-overlapping $0 \leq t_1 < t_2 < t_3 < t_4$, we have $B_{t_2} - B_{t_1}$ independent from $B_{t_4} - B_{t_3}$
	
	\item [(iii)] (\textit{Normal, stationary increments}) $B_t - B_s \sim \mathcal N(0, t-s)$ for any $0 \leq s < t$
	
	\item [(iv)]  (\textit{Continuity of paths}) The sample paths of $B_t$ are continuous
\end{itemize}

\vspace{6mm}
\begin{itemize}
\item Brownian motion is the only stochastic process with stationary and independent increments that's also continuous

\vspace{-3mm}
\item Einstein (1905) uses Brownian motion to model motion of particles

\vspace{-3mm}
\item Brownian motion is a Markov process

\vspace{-3mm}
\item $B_t \sim \mathcal N(0, t)$

\vspace{-3mm}
\item Brownian motion is nowhere differentiable
\end{itemize}
}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}

{\small
\begin{itemize}
\item Stochastic differential equations (SDEs) add noise / uncertainty to ordinary differential equations (ODEs)

\item Start with $\dot X_t = \mu X_t$ with solution $X_t = X_0 e^{\mu t}$

\item Rewrite as $d X_t = \mu X_t dt$ and ``add noise'' (using Brownian motion):
\begin{equation*}
	dX_t = \mu X_t dt + \sigma X_t dB_t
\end{equation*}

\item Important: $dB_t \sim \mathcal N(0, dt)$ because 
\begin{equation*}
	dB_t \approx B_{t + \Delta} - B_t \sim \mathcal N(0, t +\Delta - t = \mathcal N(0, \Delta)
\end{equation*}
and now take $\Delta \to dt$ (continuous-time limit)

\item Alternatively: $B_{t + \Delta} - B_t \sim \mathcal N(0, \Delta) \sim \epsilon_t \sqrt{\Delta}$ where $\epsilon_t \sim \mathcal N(0, 1)$. So as $\Delta \to dt$,
\begin{align*}
	\mathbb E(dB_t) &= \mathbb E(\epsilon_t \sqrt{dt}) = 0 \\
	\mathbb E[(dB_t)^2] &= \mathbb E[(\epsilon_t \sqrt{dt})^2] = dt
\end{align*}
\end{itemize}
}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}

{\small
\begin{itemize}
\item Suppose we have a function of Brownian motion, $X_t = f(t, B_t)$

\item We know how Brownian motion $dB_t$ evolves, what about $dX_t$? (That's like $\dot X_t$)

\item Answer: \textbf{Ito's lemma} (core building block of stochastic calculus)
\begin{align*}
	dX_t = d f(t, B_t)  = \partial_t f(t, B_t) dt + \frac{1}{2} \partial_{xx} f(t, B_t) dt + \partial_x f(t, B_t) dB_t
\end{align*}

\item Will not prove this, but heuristically: $(dt)^2 \to 0$ and $(dB_t)^2 \to dt$

\item For example from previous slide, $dX_t = \mu X_t dt + \sigma X_t dB_t$:
\begin{equation*}
	X_t = X_0 e^{\mu t - \frac{\sigma^2}{2} t + \sigma B_t}
\end{equation*}

\item This is called \textit{geometric Brownian motion} (used to model stock prices)

\item \textit{Ornstein-Uhlenbeck (OU) process} is a popular model for earnings risk and income fluctuations (think: continuous-time AR(1) process):
\begin{equation*}
	dz_t = \theta(\bar z - z_t) dt + \sigma dB_t
\end{equation*}
\end{itemize}
}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%  SLIDE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}
	
	{\small
		\begin{itemize}
			\item Very important class is the \textbf{diffusion process}
			
			\item They take the form (not the formal definition)
			\begin{equation*}
				dX_t = \mu(t, X_t) dt + \sigma(t, X_t) dB_t
			\end{equation*}
			where $\mu(\cdot)$ is the \textit{drift} and $\sigma(t, X_t)$ the \textit{diffusion} (volatility) parameter of the process 
			
			\item This is a shorthand for the (stochastic) integral equation 
			\begin{equation*}
				X_t = X_0 + \int_0^t \mu(s, X_s) ds + \int_0^t \sigma(s, X_s) dB_s
			\end{equation*}
			
		\end{itemize}
	}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix


\end{document}









